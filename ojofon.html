<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Gran Hermano - Detector Facial</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      height: 100%;
      font-family: 'Arial', sans-serif;
      display: flex;
      align-items: center;
      justify-content: center;
      background: linear-gradient(45deg, #1a1a2e, #16213e);
      text-align: center;
      color: #fff;
      overflow: hidden;
    }

    .wrapper {
      max-width: 90%;
      background: rgba(0, 0, 20, 0.7);
      border-radius: 20px;
      padding: 30px;
      box-shadow: 0 10px 30px rgba(0, 0, 0, 0.5);
      backdrop-filter: blur(10px);
      border: 1px solid rgba(0, 255, 136, 0.3);
    }

    h1 {
      font-size: 1.6em;
      margin-bottom: 1.5em;
      color: #00ff88;
      text-shadow: 0 0 10px rgba(0, 255, 136, 0.5);
      letter-spacing: 1px;
    }

    .eye-container {
      position: relative;
      width: 300px;
      height: 150px;
      margin: 0 auto 30px;
      transform: scale(1.1);
      transition: transform 0.3s;
    }

    .eye-image {
      width: 100%;
      height: auto;
      display: block;
      filter: drop-shadow(0 0 15px rgba(0, 255, 136, 0.5));
    }

    .pupil-video {
      position: absolute;
      top: 50%;
      left: 50%;
      width: 80px;
      height: 80px;
      transform: translate(-50%, -50%);
      border-radius: 50%;
      overflow: hidden;
      border: 2px solid #00ff88;
      z-index: 2;
      background: black;
      box-shadow: 0 0 20px rgba(0, 255, 136, 0.7);
    }

    .pupil-video video {
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: scaleX(-1); /* efecto espejo */
    }

    #btnDiscover {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      width: 60px;
      height: 60px;
      border-radius: 50%;
      border: 3px solid #00ff88;
      background: rgba(0, 0, 20, 0.8);
      color: #00ff88;
      cursor: pointer;
      font-size: 0.9em;
      font-weight: bold;
      z-index: 3;
      box-shadow: 0 0 20px rgba(0, 255, 136, 0.5);
      transition: all 0.3s;
    }

    #btnDiscover:hover {
      background: rgba(0, 255, 136, 0.2);
      transform: translate(-50%, -50%) scale(1.1);
    }

    .error {
      color: #ff4d6d;
      margin-top: 1.5em;
      font-size: 0.9em;
      min-height: 1.5em;
    }

    .status {
      color: #00ff88;
      margin-top: 1em;
      font-size: 0.9em;
      min-height: 1.5em;
    }

    .overlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      z-index: 5;
      pointer-events: none;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
      transform: scaleX(-1);
    }

    .instructions {
      margin-top: 25px;
      color: #a0a0dd;
      font-size: 0.85em;
      line-height: 1.5;
    }

    .feature {
      display: inline-block;
      background: rgba(0, 255, 136, 0.1);
      color: #00ff88;
      padding: 2px 8px;
      border-radius: 4px;
      margin: 0 3px;
    }
  </style>
</head>
<body>
  <div class="wrapper">
    <h1>Tú miras tu esmarfon,<br>tu esmarfon a ti te mira</h1>

    <div class="eye-container">
      <img src="data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='300' height='150' viewBox='0 0 300 150'><path d='M150,50 Q225,75 150,100 Q75,75 150,50' fill='none' stroke='%2300ff88' stroke-width='2'/></svg>" alt="Ojo" class="eye-image">
      <div class="pupil-video">
        <video id="preview" autoplay playsinline muted></video>
        <div class="overlay">
          <canvas id="overlayCanvas"></canvas>
        </div>
      </div>
      <button id="btnDiscover">INICIAR</button>
    </div>

    <p id="msg" class="error"></p>
    <p id="status" class="status"></p>
    
    <div class="instructions">
      <p>El sistema detectará y resaltará con <span class="feature">contornos verdes</span> tus movimientos faciales</p>
    </div>
  </div>

  <!-- Incluimos la biblioteca de seguimiento facial -->
  <script src="https://cdn.jsdelivr.net/npm/clmtrackr@1.1.2/build/clmtrackr.min.js"></script>
  
  <script>
    const btn = document.getElementById('btnDiscover');
    const video = document.getElementById('preview');
    const msg = document.getElementById('msg');
    const statusEl = document.getElementById('status');
    const overlayCanvas = document.getElementById('overlayCanvas');
    const ctx = overlayCanvas.getContext('2d');
    
    // Variables para el seguimiento facial
    let ctracker;
    let detectionActive = false;
    let lastPositions = {};
    let movementThreshold = 2; // Umbral de movimiento
    
    // Tamaño del canvas de superposición
    overlayCanvas.width = 80;
    overlayCanvas.height = 80;
    
    // Inicializar el rastreador facial
    function initFaceTracking() {
      ctracker = new clm.tracker();
      ctracker.init();
      ctracker.start(video);
      detectionActive = true;
      statusEl.textContent = "Detectando movimientos...";
      requestAnimationFrame(detectMovement);
    }
    
    // Detectar movimientos faciales
    function detectMovement() {
      if (!detectionActive) return;
      
      // Obtener las posiciones actuales de los puntos faciales
      const positions = ctracker.getCurrentPosition();
      
      if (positions) {
        ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
        
        // Comprobar movimiento para cada punto
        for (let i = 0; i < positions.length; i++) {
          const point = positions[i];
          
          // Verificar si tenemos una posición anterior para comparar
          if (lastPositions[i]) {
            const dx = point[0] - lastPositions[i][0];
            const dy = point[1] - lastPositions[i][1];
            const distance = Math.sqrt(dx * dx + dy * dy);
            
            // Si el movimiento supera el umbral, dibujar un contorno
            if (distance > movementThreshold) {
              // Dibujar un pequeño círculo verde en el punto en movimiento
              ctx.beginPath();
              ctx.arc(point[0], point[1], 3, 0, 2 * Math.PI);
              ctx.strokeStyle = '#00ff88';
              ctx.lineWidth = 2;
              ctx.stroke();
              
              // Dibujar un contorno alrededor de la zona de la cara donde hay movimiento
              if (i >= 18 && i <= 22) { // Frente/cejas
                drawFeatureContour(positions, 18, 22, '#00ff88');
              } else if (i >= 23 && i <= 26) { // Ojo izquierdo
                drawFeatureContour(positions, 23, 26, '#00ff88');
              } else if (i >= 27 && i <= 30) { // Ojo derecho
                drawFeatureContour(positions, 27, 30, '#00ff88');
              } else if (i >= 48 && i <= 54) { // Boca
                drawFeatureContour(positions, 48, 54, '#00ff88');
              }
            }
          }
          
          // Guardar la posición actual para la próxima comparación
          lastPositions[i] = [point[0], point[1]];
        }
      }
      
      requestAnimationFrame(detectMovement);
    }
    
    // Dibujar contorno alrededor de un grupo de puntos
    function drawFeatureContour(positions, start, end, color) {
      ctx.beginPath();
      ctx.moveTo(positions[start][0], positions[start][1]);
      
      for (let i = start + 1; i <= end; i++) {
        ctx.lineTo(positions[i][0], positions[i][1]);
      }
      
      // Volver al punto inicial para cerrar el contorno
      ctx.lineTo(positions[start][0], positions[start][1]);
      
      ctx.strokeStyle = color;
      ctx.lineWidth = 1;
      ctx.stroke();
    }
    
    // Iniciar la cámara
    btn.addEventListener('click', async () => {
      msg.textContent = '';
      statusEl.textContent = "Iniciando cámara...";
      
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'user' },
          audio: false
        });
        
        video.srcObject = stream;
        btn.style.display = 'none';
        statusEl.textContent = "Cargando detector facial...";
        
        // Esperar a que el video esté cargado para iniciar el seguimiento
        video.onloadedmetadata = () => {
          initFaceTracking();
        };
      } catch (e) {
        console.error(e);
        msg.textContent = 'Error: No se pudo acceder a la cámara.';
        statusEl.textContent = "";
      }
    });
    
    // Mensaje inicial
    statusEl.textContent = "Presiona INICIAR para comenzar";
  </script>
</body>
</html>
